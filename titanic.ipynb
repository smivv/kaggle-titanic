{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.feature_extraction.dict_vectorizer import DictVectorizer\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.metrics.classification import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "INPUT_DIR = '../input'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to extract titles from passenger names\n",
    "def get_title(name):\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    # If the title exists, extract and return it.\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def min_max_scale(train_data, test_data, cat_cols):\n",
    "    \n",
    "    data = pd.concat([train_data, test_data])\n",
    "    \n",
    "    # numeric attributes\n",
    "    num_data = data.drop(cat_cols, axis=1)\n",
    "    \n",
    "    # fit scaler on all data\n",
    "    scaler = MinMaxScaler().fit(num_data)\n",
    "    \n",
    "    # transform all data with scaler\n",
    "    train_data = scaler.transform(train_data.drop(cat_cols, axis=1))\n",
    "    test_data = scaler.transform(test_data.drop(cat_cols, axis=1))\n",
    "    \n",
    "    # scale to <0,1>\n",
    "    num_train_data = pd.DataFrame(train_data)\n",
    "    num_test_data = pd.DataFrame(test_data)\n",
    "\n",
    "    # fill nan with mean column values\n",
    "    num_train_data.fillna(data.mean(), inplace=True)\n",
    "    num_test_data.fillna(data.mean(), inplace=True)\n",
    "\n",
    "    return num_train_data, num_test_data\n",
    "\n",
    "\n",
    "def cat_vectorize(train_data, test_data, num_cols):\n",
    "    # categorical attributes\n",
    "    cat_train_data = train_data.drop(num_cols, axis=1)\n",
    "    cat_test_data = test_data.drop(num_cols, axis=1)\n",
    "\n",
    "    cat_train_data.fillna('NA', inplace=True)\n",
    "    cat_test_data.fillna('NA', inplace=True)\n",
    "\n",
    "    cat_train_data_values = cat_train_data.T.to_dict().values()\n",
    "    cat_test_data_values = cat_test_data.T.to_dict().values()\n",
    "\n",
    "    # vectorize (encode as one hot)\n",
    "    vectorizer = DictVectorizer(sparse=False)\n",
    "    vec_train_data = vectorizer.fit_transform(cat_train_data_values)\n",
    "    vec_test_data = vectorizer.transform(cat_test_data_values)\n",
    "\n",
    "    return vec_train_data, vec_test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  \n3      0            113803  53.1000  C123        S  \n4      0            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "\"\"\" -------------------------------------- Data loading ---------------------------------------- \"\"\"\n",
    "\n",
    "# load dataframes\n",
    "df_train = pd.read_csv(os.path.join(INPUT_DIR, 'train.csv'))\n",
    "df_test = pd.read_csv(os.path.join(INPUT_DIR, 'test.csv'))\n",
    "\n",
    "df_full = [df_train, df_test]\n",
    "\n",
    "print(df_train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n5            6         0       3   \n6            7         0       1   \n7            8         0       3   \n8            9         1       3   \n9           10         1       2   \n\n                                                Name  Sex  Age  SibSp  Parch  \\\n0                            Braund, Mr. Owen Harris    1    1      1      0   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...    0    2      1      0   \n2                             Heikkinen, Miss. Laina    0    1      0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    0    2      1      0   \n4                           Allen, Mr. William Henry    1    2      0      0   \n5                                   Moran, Mr. James    1    1      0      0   \n6                            McCarthy, Mr. Timothy J    1    3      0      0   \n7                     Palsson, Master. Gosta Leonard    1    0      3      1   \n8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)    0    1      0      2   \n9                Nasser, Mrs. Nicholas (Adele Achem)    0    0      1      0   \n\n             Ticket  Fare Cabin  Embarked  Name_length  Has_Cabin  FamilySize  \\\n0         A/5 21171     0   NaN         0           23          0           2   \n1          PC 17599     3   C85         1           51          1           2   \n2  STON/O2. 3101282     1   NaN         0           22          0           1   \n3            113803     3  C123         0           44          1           2   \n4            373450     1   NaN         0           24          0           1   \n5            330877     1   NaN         2           16          0           1   \n6             17463     3   E46         0           23          1           1   \n7            349909     2   NaN         0           30          0           5   \n8            347742     1   NaN         0           49          0           3   \n9            237736     2   NaN         1           35          0           2   \n\n   IsAlone  Title  \n0        0      1  \n1        0      3  \n2        1      2  \n3        0      3  \n4        1      1  \n5        1      1  \n6        1      1  \n7        0      4  \n8        0      3  \n9        0      3  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "\"\"\" -------------------------------------- Feature Engineering ---------------------------------------- \"\"\"\n",
    "\n",
    "for dataset in df_full:\n",
    "    dataset['Name_length'] = dataset['Name'].apply(len)\n",
    "\n",
    "    # Feature that tells whether a passenger had a cabin on the Titanic\n",
    "    dataset['Has_Cabin'] = dataset[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
    "\n",
    "    # Create new feature FamilySize as a combination of SibSp and Parch\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "\n",
    "    # Create new feature IsAlone from FamilySize\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "\n",
    "    # Remove all NULLS in the Embarked column\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna('S')\n",
    "\n",
    "    # Remove all NULLS in the Fare column and create a new feature CategoricalFare\n",
    "    dataset['Fare'] = dataset['Fare'].fillna(df_train['Fare'].median())\n",
    "\n",
    "    # df_train['CategoricalFare'] = pandas.qcut(df_train['Fare'], 4)\n",
    "\n",
    "    # Create a New feature CategoricalAge\n",
    "    age_avg = dataset['Age'].mean()\n",
    "    age_std = dataset['Age'].std()\n",
    "    age_null_count = dataset['Age'].isnull().sum()\n",
    "    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n",
    "    dataset['Age'][np.isnan(dataset['Age'])] = age_null_random_list\n",
    "    dataset['Age'] = dataset['Age'].astype(int)\n",
    "\n",
    "    # df_train['CategoricalAge'] = pandas.cut(df_train['Age'], 5)\n",
    "\n",
    "    # Create a new feature Title, containing the titles of passenger names\n",
    "    dataset['Title'] = dataset['Name'].apply(get_title)\n",
    "\n",
    "    # Group all non-common titles into one single grouping \"Rare\"\n",
    "    dataset['Title'] = dataset['Title'].replace(\n",
    "        ['Lady', 'Countess', 'Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "    # Mapping Sex\n",
    "    dataset['Sex'] = dataset['Sex'].map({'female': 0, 'male': 1}).astype(int)\n",
    "\n",
    "    # Mapping titles\n",
    "    title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)\n",
    "\n",
    "    # Mapping Embarked\n",
    "    dataset['Embarked'] = dataset['Embarked'].map({'S': 0, 'C': 1, 'Q': 2}).astype(int)\n",
    "\n",
    "    # Mapping Fare\n",
    "    dataset.loc[dataset['Fare'] <= 7.91, 'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare'] = 2\n",
    "    dataset.loc[dataset['Fare'] > 31, 'Fare'] = 3\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "\n",
    "    # Mapping Age\n",
    "    dataset.loc[dataset['Age'] <= 16, 'Age'] = 0\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "    dataset.loc[dataset['Age'] > 64, 'Age'] = 4\n",
    "\n",
    "print(df_train.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PassengerId', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Name_length', 'Has_Cabin', 'FamilySize', 'IsAlone', 'Title'] ['Name', 'Ticket', 'Cabin']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64 were all converted to float64 by MinMaxScaler.\n  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" -------------------------------------- Feature preparation ---------------------------------------- \"\"\"\n",
    "\n",
    "label_column = 'Survived'\n",
    "\n",
    "# get all column names\n",
    "cols = list(df_train.columns.values)\n",
    "\n",
    "# numeric columns\n",
    "num_cols = [e for e in df_train.select_dtypes(include=[np.number]).columns.tolist() if e != label_column]\n",
    "\n",
    "# categorical columns\n",
    "cat_cols = [e for e in cols if e not in num_cols and e != label_column]\n",
    "\n",
    "print(num_cols, cat_cols)\n",
    "\n",
    "x_train, y_train = df_train.drop(label_column, axis=1), df_train[label_column]\n",
    "x_test = df_test\n",
    "\n",
    "# scale everything to [0, 1]\n",
    "x_num_train, x_num_test = min_max_scale(x_train, x_test, cat_cols)\n",
    "\n",
    "# vectorize categorical columns\n",
    "vec_x_cat_train, vec_x_cat_test = cat_vectorize(x_train, x_test, num_cols)\n",
    "\n",
    "# build the feature vector\n",
    "x_train = np.hstack((x_num_train, vec_x_cat_train))\n",
    "x_test = np.hstack((x_num_test, vec_x_cat_test))\n",
    "\n",
    "# labels or target attribute\n",
    "y_train = y_train.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" -------------------------------------- Cross validation ---------------------------------------- \"\"\"\n",
    "\n",
    "# split the data into train and test\n",
    "xs_train, xs_test, ys_train, ys_test = train_test_split(x_train, y_train, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" -------------------------------------- Best Linear Regression search ---------------------------------------- \"\"\"\n",
    "\n",
    "# Create the parameter grid \n",
    "gbm_param_grid = {\n",
    "    'n_estimators': range(8, 20),\n",
    "    'max_depth': range(6, 10),\n",
    "    'learning_rate': [.4, .45, .5, .55, .6],\n",
    "    'colsample_bytree': [.6, .7, .8, .9, 1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 50 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'n_estimators': 15, 'max_depth': 8, 'learning_rate': 0.5, 'colsample_bytree': 0.6}\nBest accuracy found:  0.8258426966292135\n"
     ]
    }
   ],
   "source": [
    "\"\"\" -------------------------------------- Best params search ---------------------------------------- \"\"\"\n",
    "\n",
    "# Create the parameter grid \n",
    "gbm_param_grid = {\n",
    "    'n_estimators': range(8, 20),\n",
    "    'max_depth': range(6, 10),\n",
    "    'learning_rate': [.4, .45, .5, .55, .6],\n",
    "    'colsample_bytree': [.6, .7, .8, .9, 1]\n",
    "}\n",
    "\n",
    "# Instantiate the regressor: gbm\n",
    "gbm = XGBClassifier(n_estimators=10)\n",
    "\n",
    "# Perform random search: grid_mse\n",
    "xgb_random = RandomizedSearchCV(param_distributions=gbm_param_grid,\n",
    "                                estimator=gbm, scoring=\"accuracy\",\n",
    "                                verbose=1, n_iter=50, cv=4)\n",
    "\n",
    "# Fit randomized_mse to the data\n",
    "xgb_random.fit(x_train, y_train)\n",
    "\n",
    "# Print the best parameters and lowest RMSE\n",
    "print(\"Best parameters found: \", xgb_random.best_params_)\n",
    "print(\"Best accuracy found: \", xgb_random.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = xgb_random.predict(x_test)\n",
    "submission = pd.DataFrame({'PassengerId': df_test['PassengerId'], 'Survived': pred})\n",
    "submission.to_csv('gender_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
